{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-15T15:20:03.802472Z",
     "start_time": "2024-11-15T15:20:02.400399Z"
    }
   },
   "source": [
    "import pprint\n",
    "import time\n",
    "\n",
    "import zmq\n",
    "from sympy.physics.units import current\n",
    "\n",
    "ctx = zmq.Context()\n",
    "# The REQ talks to Pupil remote and receives the session unique IPC SUB PORT\n",
    "socket = ctx.socket(zmq.REQ)\n",
    "\n",
    "ip = 'localhost'  # If you talk to a different machine use its IP.\n",
    "port = 50020  # The port defaults to 50020. Set in Pupil Capture GUI.\n",
    "\n",
    "socket.connect(f'tcp://{ip}:{port}')\n",
    "\n",
    "# Request 'SUB_PORT' for reading data\n",
    "socket.send_string('SUB_PORT')\n",
    "sub_port = socket.recv_string()\n",
    "\n",
    "# Request 'PUB_PORT' for writing data\n",
    "socket.send_string('PUB_PORT')\n",
    "pub_port = socket.recv_string()\n",
    "\n",
    "socket.close()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:20:03.843279Z",
     "start_time": "2024-11-15T15:20:03.821353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import msgpack\n",
    "\n",
    "socket = ctx.socket(zmq.REQ)\n",
    "socket.connect(f'tcp://{ip}:{port}')\n",
    "\n",
    "# Define the new configuration for fixation parameters\n",
    "notification = {\n",
    "    \"subject\": \"start_plugin\",\n",
    "    \"name\": \"Fixation_Detector\",\n",
    "    \"args\": {\n",
    "        \"max_dispersion\": 5,\n",
    "        \"min_duration\": 600,\n",
    "    },\n",
    "}\n",
    "\n",
    "topic = 'notify.' + notification['subject']\n",
    "payload = msgpack.dumps(notification)\n",
    "socket.send_string(topic, flags=zmq.SNDMORE)\n",
    "socket.send(payload)\n",
    "socket.close()"
   ],
   "id": "b8aa419f04613e2f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:20:04.373320Z",
     "start_time": "2024-11-15T15:20:04.161317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of the lamp\n",
    "url = \"http://10.2.2.33:1880/r402/theglobe\"\n",
    "\n",
    "# Define the payload to turn the lamp off\n",
    "payload = {\n",
    "    \"on\": True,  # Turn the lamp off\n",
    "    \"brightness\": 100\n",
    "}\n",
    "\n",
    "# Send the PUT request to change the state of the lamp\n",
    "try:\n",
    "    response = requests.put(url, json=payload)\n",
    "    print(response)\n",
    "    if response.status_code == 200:\n",
    "        print(\"The lamp has been turned on successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to turn off the lamp. Status code: {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    \n",
    "# Sent a GET request to retrieve the Thing Description\n",
    "response = requests.get(url)\n",
    "print(response)"
   ],
   "id": "c25b0236d3860b69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "The lamp has been turned on successfully.\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:20:04.440368Z",
     "start_time": "2024-11-15T15:20:04.433187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup ZeroMQ context and subscriber socket\n",
    "ctx = zmq.Context()\n",
    "\n",
    "def create_socket(ctx_c, ip_c, topics):\n",
    "    sub = ctx_c.socket(zmq.SUB)\n",
    "    sub.connect(f'tcp://{ip_c}:{sub_port}')\n",
    "    for topic in topics:\n",
    "        sub.subscribe(topic)\n",
    "    return sub"
   ],
   "id": "c29bcc4b585e0cb6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:20:56.094359Z",
     "start_time": "2024-11-15T15:20:56.046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import msgpack\n",
    "\n",
    "\n",
    "def receive_data(sock):\n",
    "    \"\"\"Receive data from the socket and return the topic and payload.\"\"\"\n",
    "    data = sock.recv_multipart()\n",
    "    t = data[0].decode(\"utf-8\")\n",
    "    p = msgpack.unpackb(data[1], raw=False) if t == 'fixations' else data[2]\n",
    "    return t, p\n",
    "\n",
    "def decode_frame(frame_data):\n",
    "    \"\"\"Decode frame data from socket payload.\"\"\"\n",
    "    return cv2.imdecode(np.frombuffer(frame_data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "def get_object_in_gaze(gaze, r):\n",
    "    for result in r:\n",
    "        boxes = result.boxes\n",
    "        classes = boxes.cls\n",
    "        for i, box in enumerate(boxes.xyxyn):\n",
    "            # Check if the gaze point lies within the bounding box of detected objects\n",
    "            if box[0] <= gaze[0] <= box[2] and box[1] <= (1 - gaze[1]) <= box[3]:\n",
    "                return result.names[int(classes[i])]\n",
    "    return None\n",
    "\n",
    "def detect_camera_movement(frame1, frame2, tr=None):\n",
    "    # Convert frames to grayscale\n",
    "    prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    curr_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Parameters for optical flow (Lucas-Kanade method)\n",
    "    lk_params = dict(winSize=(21, 21), maxLevel=3, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "\n",
    "    # Detect good features to track in the first frame\n",
    "    prev_points = cv2.goodFeaturesToTrack(prev_gray, mask=None, **dict(maxCorners=100, qualityLevel=0.3, minDistance=7))\n",
    "\n",
    "    # Calculate optical flow (track points from prev_frame to curr_frame)\n",
    "    next_points, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_points, None, **lk_params)\n",
    "\n",
    "    # Select good points (where the flow has been successfully found)\n",
    "    good_prev_points = prev_points[status == 1]\n",
    "    good_next_points = next_points[status == 1]\n",
    "\n",
    "    # Calculate the displacement of points\n",
    "    displacements = good_next_points - good_prev_points\n",
    "    avg_displacement = displacements.mean(axis=0)\n",
    "\n",
    "    # Direction based on average displacement\n",
    "    dx, dy = avg_displacement\n",
    "    \n",
    "    if tr:\n",
    "        if abs(dx) > tr or abs(dy) > tr:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    tr_v = 30\n",
    "    tr_h = 30\n",
    "    if abs(dx) > abs(dy):  # Horizontal movement\n",
    "        if dx > tr_h:\n",
    "            return f\"Left\"\n",
    "        elif dx < -1 * tr_h:\n",
    "            return f\"Right\"\n",
    "    else:  # Vertical movement\n",
    "        if dy > tr_v:\n",
    "            return f\"Up\"\n",
    "        elif dy < -1 * tr_v:\n",
    "            return f\"Down\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def process_gesture(head_direction, state):\n",
    "    \"\"\"Update gesture state and determine if a gesture is completed.\"\"\"\n",
    "    interaction = None\n",
    "    \n",
    "    if head_direction == 'Up' and state is None:\n",
    "        state = 'Up'\n",
    "    elif head_direction is None and state == 'Up':\n",
    "        interaction = \"Increase gesture detected (up followed by down)\"\n",
    "        state = None\n",
    "    elif head_direction == 'Down' and state is None:\n",
    "        state = 'Down'\n",
    "    elif head_direction is None and state == 'Down':\n",
    "        interaction = \"Decrease gesture detected (down followed by up)\"\n",
    "        state = None\n",
    "    elif head_direction == 'Left' and state is None:\n",
    "        state = 'Left'\n",
    "    elif head_direction is None and state == 'Left':\n",
    "        interaction = \"Left gesture detected\"\n",
    "        state = None\n",
    "    elif head_direction == 'Right' and state is None:\n",
    "        state = 'Right'\n",
    "    elif head_direction is None and state == 'Right':\n",
    "        interaction = \"Right gesture detected\"\n",
    "        state = None\n",
    "    \n",
    "    return interaction, state\n",
    "\n"
   ],
   "id": "e04fbc22c8d96f09",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:20:56.562519Z",
     "start_time": "2024-11-15T15:20:56.532444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "def set_lamp_brightness(mode):\n",
    "    # URL for the Thing Description (base URL provided in the TD itself)\n",
    "    td_url = \"http://10.2.2.33:1880/r402/theglobe\"\n",
    "    \n",
    "    try:\n",
    "        # Send a GET request to retrieve the Thing Description\n",
    "        response = requests.get(td_url)\n",
    "        \n",
    "        # get the current brightness of the lamp\n",
    "        curr_brighness = response.json()[\"brightness\"]\n",
    "        lamp_brighness = curr_brighness\n",
    "        \n",
    "        # if mode is increase, increase the brightness by 10 if it is less than 100\n",
    "        if mode == \"Increase\":\n",
    "            if curr_brighness <= 80:\n",
    "                lamp_brighness += 20\n",
    "            else:\n",
    "                lamp_brighness = 100\n",
    "        # if mode is decrease, decrease the brightness by 10 if it is greater than 0\n",
    "        elif mode == \"Decrease\":\n",
    "            if curr_brighness >= 20:\n",
    "                lamp_brighness -= 20\n",
    "            else:\n",
    "                lamp_brighness = 0\n",
    "    \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Define the payload to turn the lamp off\n",
    "            payload = {\n",
    "                \"brightness\": lamp_brighness\n",
    "            }\n",
    "            \n",
    "            # Send the PUT request to change the state of the lamp\n",
    "            try:\n",
    "                response = requests.put(td_url, json=payload)\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"Lamp brightness has been set to {lamp_brighness}.\")\n",
    "                else:\n",
    "                    print(f\"Failed to turn off the lamp. Status code: {response.status_code}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve Thing Description. Status code: {response.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "def set_lamp_color(mode):\n",
    "    # URL for the Thing Description (base URL provided in the TD itself)\n",
    "    td_url = \"http://10.2.2.33:1880/r402/theglobe\"\n",
    "    colors = [\"yellow\", \"red\", \"green\", \"blue\", \"magenta\"]\n",
    "    \n",
    "    try:\n",
    "        # Send a GET request to retrieve the Thing Description\n",
    "        response = requests.get(td_url)\n",
    "        \n",
    "        # get the current color of the lamp\n",
    "        curr_color = response.json()[\"color\"]\n",
    "        if curr_color in colors:\n",
    "            curr_index = colors.index(curr_color)\n",
    "        else:\n",
    "            curr_index = 0\n",
    "        \n",
    "        # if mode is increase, increase the brightness by 10 if it is less than 100\n",
    "        if mode == \"Left\":\n",
    "            if curr_index == 0:\n",
    "                curr_index = len(colors) - 1\n",
    "            else:\n",
    "                curr_index = curr_index - 1\n",
    "        # if mode is decrease, decrease the brightness by 10 if it is greater than 0\n",
    "        elif mode == \"Right\":\n",
    "            if curr_index == len(colors) - 1:\n",
    "                curr_index = 0\n",
    "            else:\n",
    "                curr_index = curr_index + 1\n",
    "    \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Define the payload to turn the lamp off\n",
    "            payload = {\n",
    "                \"color\": colors[curr_index]\n",
    "            }\n",
    "            \n",
    "            # Send the PUT request to change the state of the lamp\n",
    "            try:\n",
    "                response = requests.put(td_url, json=payload)\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"Lamp color has been set to {colors[curr_index]}.\")\n",
    "                else:\n",
    "                    print(f\"Failed to set lamp color. Status code: {response.status_code}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve Thing Description. Status code: {response.status_code}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ],
   "id": "244fbda7320df061",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:23:53.662156Z",
     "start_time": "2024-11-15T15:23:14.193462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "from ultralytics import YOLO\n",
    "from zmq_tools import *\n",
    "import time\n",
    "\n",
    "ctx = zmq.Context()\n",
    "requester = ctx.socket(zmq.REQ)\n",
    "requester.connect('tcp://localhost:50020') #change ip if using remote machine\n",
    "\n",
    "# request 'SUB_PORT' for reading data\n",
    "requester.send_string('SUB_PORT')\n",
    "ipc_sub_port = requester.recv_string()\n",
    "\n",
    "model = YOLO(\"../.local/models/object_detection/yolov11n_trained.pt\", verbose=False) \n",
    "\n",
    "last_frame = None\n",
    "obj_detected = None\n",
    "\n",
    "fixation_detected = False\n",
    "movement_state = None\n",
    "while not fixation_detected:\n",
    "    print(\"Waiting for fixation\")\n",
    "    socket_fixations = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('fixations',))\n",
    "    _, payload = socket_fixations.recv()\n",
    "    gaze_position = payload[\"norm_pos\"]\n",
    "    print(\"Fixation detected\")\n",
    "    \n",
    "    print(\"Waiting for frame\")\n",
    "    socket_frames = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('frame.world',))\n",
    "    _, payload = socket_frames.recv()\n",
    "    curr_frame = decode_frame(payload['__raw_data__'][0])\n",
    "    print(\"Frame received\")\n",
    "    \n",
    "    if last_frame is None and obj_detected is None:\n",
    "        last_frame = curr_frame\n",
    "        obj_detected = model(last_frame)\n",
    "    \n",
    "    print(\"Checking for camera movement\")\n",
    "    image_shift = detect_camera_movement(last_frame, curr_frame, tr=5)\n",
    "    if image_shift:\n",
    "        print(\"Camera movement detected\")\n",
    "        obj_detected = model(curr_frame)\n",
    "        last_frame = curr_frame\n",
    "    \n",
    "    print(\"Checking for object in gaze\")\n",
    "    obj = get_object_in_gaze(gaze_position, obj_detected)\n",
    "    if obj and \"HueLamp\" in obj:\n",
    "        print(\"Object detected in gaze, starting gesture detection\")\n",
    "        gesture_detected = False\n",
    "        while not gesture_detected:\n",
    "            socket_frames = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('frame.world',))\n",
    "            _, payload = socket_frames.recv()\n",
    "            frame = decode_frame(payload['__raw_data__'][0])\n",
    "            direction = detect_camera_movement(curr_frame, frame)\n",
    "                \n",
    "            gesture, movement_state = process_gesture(direction, movement_state)\n",
    "            if gesture:\n",
    "                if \"Increase\" in gesture:\n",
    "                    print(gesture)\n",
    "                    set_lamp_brightness(\"Increase\")\n",
    "                elif \"Decrease\" in gesture:\n",
    "                    print(gesture)\n",
    "                    set_lamp_brightness(\"Decrease\")\n",
    "                elif \"Left\" in gesture:\n",
    "                    set_lamp_color(\"Left\")\n",
    "                    print(gesture)\n",
    "                elif \"Right\" in gesture:\n",
    "                    set_lamp_color(\"Right\")\n",
    "                    print(gesture)\n",
    "                gesture_detected = True\n",
    "                time.sleep(0.5)\n",
    "            "
   ],
   "id": "b72c7c8295a77f38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "\n",
      "0: 384x640 1 HueLampWhiteHalfRound, 17.7ms\n",
      "Speed: 3.4ms preprocess, 17.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for camera movement\n",
      "Checking for object in gaze\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampYellow, 17.4ms\n",
      "Speed: 2.4ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Lamp color has been set to red.\n",
      "Right gesture detected\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampRed, 16.8ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Lamp color has been set to green.\n",
      "Right gesture detected\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampGreen, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Decrease gesture detected (down followed by up)\n",
      "Lamp brightness has been set to 80.\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampGreen, 25.7ms\n",
      "Speed: 5.3ms preprocess, 25.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Decrease gesture detected (down followed by up)\n",
      "Lamp brightness has been set to 60.\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampGreen, 28.4ms\n",
      "Speed: 2.1ms preprocess, 28.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Lamp color has been set to red.\n",
      "Left gesture detected\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampRed, 25.5ms\n",
      "Speed: 2.3ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Lamp color has been set to yellow.\n",
      "Left gesture detected\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampYellow, 19.4ms\n",
      "Speed: 2.0ms preprocess, 19.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Increase gesture detected (up followed by down)\n",
      "Lamp brightness has been set to 80.\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampYellow, 20.9ms\n",
      "Speed: 3.0ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Increase gesture detected (up followed by down)\n",
      "Lamp brightness has been set to 100.\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampYellow, 17.3ms\n",
      "Speed: 2.5ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Lamp color has been set to magenta.\n",
      "Left gesture detected\n",
      "Waiting for fixation\n",
      "Fixation detected\n",
      "Waiting for frame\n",
      "Frame received\n",
      "Checking for camera movement\n",
      "Camera movement detected\n",
      "\n",
      "0: 384x640 1 HueLampPurple, 18.7ms\n",
      "Speed: 2.2ms preprocess, 18.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Checking for object in gaze\n",
      "Object detected in gaze, starting gesture detection\n",
      "Decrease gesture detected (down followed by up)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "def frame_change(frame1, frame2, threshold=200):\n",
    "    # Convert frames to grayscale\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Detect and compute keypoints and descriptors\n",
    "    kp1, des1 = orb.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "    # Create a Brute-Force Matcher\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.match(des1, des2)\n",
    "\n",
    "    # Sort matches by distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    print(len(matches))\n",
    "\n",
    "    # If matches are below the threshold, images are completely different\n",
    "    return len(matches) < threshold"
   ],
   "id": "f992f4f16bd0b622",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "socket_frames = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('frame.world',))\n",
    "_, payload = socket_frames.recv()\n",
    "curr_frame = decode_frame(payload['__raw_data__'][0])\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    socket_frames = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('frame.world',))\n",
    "    _, payload = socket_frames.recv()\n",
    "    frame = decode_frame(payload['__raw_data__'][0])\n",
    "    direction = detect_camera_movement(curr_frame, frame)\n",
    "    print(direction)\n",
    "    curr_frame = frame\n",
    "                    "
   ],
   "id": "169f63ac8acc2060",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from zmq_tools import *\n",
    "import time\n",
    "\n",
    "ctx = zmq.Context()\n",
    "requester = ctx.socket(zmq.REQ)\n",
    "requester.connect('tcp://localhost:50020') #change ip if using remote machine\n",
    "\n",
    "# request 'SUB_PORT' for reading data\n",
    "requester.send_string('SUB_PORT')\n",
    "ipc_sub_port = requester.recv_string()\n",
    "\n",
    "monitor = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('frame.world',)) #change ip if using remote machine\n",
    "\n",
    "s1 = monitor.recv()[1]\n",
    "print(s1)"
   ],
   "id": "4b90a62490c4ea8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "import pprint\n",
    "from zmq_tools import *\n",
    "import matplotlib.pyplot as plt\n",
    "ctx = zmq.Context()\n",
    "requester = ctx.socket(zmq.REQ)\n",
    "requester.connect('tcp://localhost:50020') #change ip if using remote machine\n",
    "\n",
    "# request 'SUB_PORT' for reading data\n",
    "requester.send_string('SUB_PORT')\n",
    "ipc_sub_port = requester.recv_string()\n",
    "\n",
    "while not fixation_detected:\n",
    "    socket_fixations = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('fixations',))\n",
    "    _, payload = socket_fixations.recv()\n",
    "    print(\"Fixation detected\")\n",
    "    gaze_position = payload[\"norm_pos\"]\n",
    "    pprint.pprint(payload)\n",
    "    \n",
    "    socket_frames = Msg_Receiver(ctx,'tcp://localhost:%s'%ipc_sub_port,topics=('frame.world',))\n",
    "    _, payload = socket_frames.recv()\n",
    "    curr_frame = decode_frame(payload['__raw_data__'][0])\n",
    "    \n",
    "    # plot the fixation point on the frame\n",
    "    x, y = int(gaze_position[0] * curr_frame.shape[1]), int((1 - gaze_position[1]) * curr_frame.shape[0])\n",
    "    cv2.circle(curr_frame, (x, y), 10, (255, 0, 0), -1)\n",
    "    plt.imshow(curr_frame, cmap='gray')\n",
    "    break\n",
    "    \n",
    "                \n",
    "                    \n",
    "            "
   ],
   "id": "a8cb7b8a0d7d8257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fbda9d65821a0d9b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

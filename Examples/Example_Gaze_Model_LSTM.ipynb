{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T13:09:31.049946Z",
     "start_time": "2024-10-17T13:09:31.045452Z"
    }
   },
   "source": [
    "class Config:\n",
    "    DATASET_PATH = \"../.local/datasets/PupilCoreV1_all/\"\n",
    "    MODEL_CHKPT_PATH = \"../.local/checkpoints/\"\n",
    "    \n",
    "conf = Config()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "163ab3d7fe65747e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:09:33.935695Z",
     "start_time": "2024-10-17T13:09:31.071311Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GazeDataset(Dataset):\n",
    "    CLASS_MAP = {\n",
    "        'Inspection': 0,\n",
    "        'Reading': 1,\n",
    "        'Search': 2,\n",
    "    }\n",
    "    def __init__(self, \n",
    "                 data_files, \n",
    "                 selected_cols, \n",
    "                 seq_len, \n",
    "                 transform=None,\n",
    "                 min_confidence=0.8,\n",
    "                 interpolation_method='linear'):\n",
    "        self.data_files = data_files\n",
    "        self.selected_cols = selected_cols\n",
    "        self.seq_len = seq_len\n",
    "        self.transform = transform\n",
    "        self.interpolation_method = interpolation_method\n",
    "        self.min_confidence = min_confidence\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.participant_ids = []\n",
    "        \n",
    "        for file in self.data_files:\n",
    "            participant_id = file.split('/')[-1].split('_')[0]\n",
    "            label = file.split('/')[-1].split('_')[1].split('.')[0]\n",
    "            \n",
    "            sample = self.load_single_file(file)\n",
    "            # sample = self.set_low_confidence_data_to_nan(sample)\n",
    "            # sample = self.remove_low_confidence_data(sample)\n",
    "            # sample = self.clip_data(sample)\n",
    "            sample = self.interpolate_data(sample)\n",
    "            sample = self.drop_nan_rows(sample)\n",
    "            sequences = self.split_data_into_sequences(sample)\n",
    "            \n",
    "            sequences = np.array(sequences).astype(np.float32)\n",
    "            \n",
    "            self.data.extend(sequences)  # Append sequences to the dataset\n",
    "            self.labels.extend([int(self.CLASS_MAP[label])] * len(sequences))\n",
    "            self.participant_ids.extend([int(participant_id)] * len(sequences))\n",
    "            \n",
    "        self.data = np.array(self.data)\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.participant_ids = np.array(self.participant_ids)\n",
    "        \n",
    "    def load_single_file(self, file: str):\n",
    "        raw_data = pd.read_csv(file)\n",
    "        raw_data = raw_data[self.selected_cols]\n",
    "        return raw_data\n",
    "    \n",
    "    def remove_low_confidence_data(self, df: pd.DataFrame):\n",
    "        low_confidence_data = df[df['confidence'] <= self.min_confidence]\n",
    "        print(f\"Removed {len(low_confidence_data)} low confidence data points\")\n",
    "        return df[df['confidence'] > self.min_confidence]\n",
    "    \n",
    "    def set_low_confidence_data_to_nan(self, df: pd.DataFrame):\n",
    "        df.loc[df['confidence'] <= self.min_confidence, ['norm_pos_x', 'norm_pos_y']] = np.nan\n",
    "        return df\n",
    "    \n",
    "    def clip_data(self, df: pd.DataFrame):\n",
    "        start = int(len(df) * 0.02)\n",
    "        end = int(len(df) * 0.98)\n",
    "        return df[start:end]\n",
    "    \n",
    "    def drop_nan_rows(self, df: pd.DataFrame):\n",
    "        return df.dropna()\n",
    "    \n",
    "    def interpolate_data(self, df: pd.DataFrame):\n",
    "        # Replave inf values with NaN\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        # Interpolate the NaN values\n",
    "        df = df.interpolate(method=self.interpolation_method)\n",
    "        return df\n",
    "    \n",
    "    def split_data_into_sequences(self, arr: np.ndarray):\n",
    "        # split the data into sequences of length seq_len.\n",
    "        sequences = [arr[i:i + self.seq_len] for i in range(0, len(arr), self.seq_len)]\n",
    "        # remove the last sequence if it is not of length seq_len\n",
    "        if len(sequences[-1]) != self.seq_len:\n",
    "            sequences.pop()\n",
    "        return sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1bfe2f64538f2043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:09:36.050639Z",
     "start_time": "2024-10-17T13:09:34.188597Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Define the PyTorch Lightning Module\n",
    "class GazeRNN(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size, \n",
    "                 num_layers, \n",
    "                 num_classes, \n",
    "                 rnn_type='LSTM',\n",
    "                 dropout=0,\n",
    "                 learning_rate=0.001,\n",
    "                 opt_step_size=5,\n",
    "                 opt_gamma=0.1,\n",
    "                 opt_wd=1e-5):\n",
    "        super(GazeRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.opt_step_size = opt_step_size\n",
    "        self.opt_gamma = opt_gamma\n",
    "        self.opt_wd = opt_wd\n",
    "\n",
    "        # Choose between LSTM, GRU, or vanilla RNN\n",
    "        if rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        elif rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Accuracy metric\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        if isinstance(self.rnn, nn.LSTM):\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "            out, _ = self.rnn(x, (h0, c0))\n",
    "        else:\n",
    "            out, _ = self.rnn(x, h0)\n",
    "\n",
    "        # Take the last time-step's output\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.train_acc(outputs, labels)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = self.val_acc(outputs, labels)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('lr', self.trainer.optimizers[0].param_groups[0]['lr'], on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.opt_wd)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=self.opt_step_size, gamma=self.opt_gamma)\n",
    "        # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "        return [optimizer], [scheduler]\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "2a5857d37f02b6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:09:36.136264Z",
     "start_time": "2024-10-17T13:09:36.076714Z"
    }
   },
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class GazeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, ds_train, ds_val, batch_size=64, num_workers=4):\n",
    "        super(GazeDataModule, self).__init__()\n",
    "        self.ds_train = ds_train\n",
    "        self.ds_val = ds_val\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a5e0c475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:09:36.346473Z",
     "start_time": "2024-10-17T13:09:36.164045Z"
    }
   },
   "source": [
    "df = pd.read_csv(conf.DATASET_PATH + '01_Inspection.csv')\n",
    "\n",
    "print(list(df.columns))\n",
    "\n",
    "times = df['pupil_timestamp'].values\n",
    "\n",
    "# convert the timestamps to seconds\n",
    "print(times[:5])\n",
    "window = 120\n",
    "window_duration = times[window] - times[0]\n",
    "print(f\"Window duration: {window_duration:.2f} seconds\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pupil_timestamp', 'norm_pos_x_2d_0', 'norm_pos_y_2d_0', 'diameter_2d_0', 'ellipse_center_x_2d_0', 'ellipse_center_y_2d_0', 'ellipse_axis_a_2d_0', 'ellipse_axis_b_2d_0', 'ellipse_angle_2d_0', 'norm_pos_x_2d_1', 'norm_pos_y_2d_1', 'diameter_2d_1', 'ellipse_center_x_2d_1', 'ellipse_center_y_2d_1', 'ellipse_axis_a_2d_1', 'ellipse_axis_b_2d_1', 'ellipse_angle_2d_1', 'norm_pos_x_3d_0', 'norm_pos_y_3d_0', 'diameter_3d_0', 'ellipse_center_x_3d_0', 'ellipse_center_y_3d_0', 'ellipse_axis_a_3d_0', 'ellipse_axis_b_3d_0', 'ellipse_angle_3d_0', 'diameter_3d_3d_0', 'model_confidence_3d_0', 'sphere_center_x_3d_0', 'sphere_center_y_3d_0', 'sphere_center_z_3d_0', 'sphere_radius_3d_0', 'circle_3d_center_x_3d_0', 'circle_3d_center_y_3d_0', 'circle_3d_center_z_3d_0', 'circle_3d_normal_x_3d_0', 'circle_3d_normal_y_3d_0', 'circle_3d_normal_z_3d_0', 'circle_3d_radius_3d_0', 'theta_3d_0', 'phi_3d_0', 'projected_sphere_center_x_3d_0', 'projected_sphere_center_y_3d_0', 'projected_sphere_axis_a_3d_0', 'projected_sphere_axis_b_3d_0', 'projected_sphere_angle_3d_0', 'norm_pos_x_3d_1', 'norm_pos_y_3d_1', 'diameter_3d_1', 'ellipse_center_x_3d_1', 'ellipse_center_y_3d_1', 'ellipse_axis_a_3d_1', 'ellipse_axis_b_3d_1', 'ellipse_angle_3d_1', 'diameter_3d_3d_1', 'model_confidence_3d_1', 'sphere_center_x_3d_1', 'sphere_center_y_3d_1', 'sphere_center_z_3d_1', 'sphere_radius_3d_1', 'circle_3d_center_x_3d_1', 'circle_3d_center_y_3d_1', 'circle_3d_center_z_3d_1', 'circle_3d_normal_x_3d_1', 'circle_3d_normal_y_3d_1', 'circle_3d_normal_z_3d_1', 'circle_3d_radius_3d_1', 'theta_3d_1', 'phi_3d_1', 'projected_sphere_center_x_3d_1', 'projected_sphere_center_y_3d_1', 'projected_sphere_axis_a_3d_1', 'projected_sphere_axis_b_3d_1', 'projected_sphere_angle_3d_1']\n",
      "[70066.411701 70066.419654 70066.428016 70066.43574  70066.443642]\n",
      "Window duration: 1.08 seconds\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "4b6e04a8f806e5de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:36:28.507194Z",
     "start_time": "2024-10-17T13:36:21.851371Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "col_of_interest = [\n",
    "    # 'pupil_timestamp', \n",
    "    'norm_pos_x_2d_0', 'norm_pos_y_2d_0', \n",
    "    'diameter_2d_0', \n",
    "    'ellipse_center_x_2d_0', 'ellipse_center_y_2d_0', 'ellipse_axis_a_2d_0', 'ellipse_axis_b_2d_0', 'ellipse_angle_2d_0', \n",
    "    'norm_pos_x_2d_1', 'norm_pos_y_2d_1', \n",
    "    'diameter_2d_1', \n",
    "    'ellipse_center_x_2d_1', 'ellipse_center_y_2d_1', 'ellipse_axis_a_2d_1', 'ellipse_axis_b_2d_1', 'ellipse_angle_2d_1', \n",
    "    'norm_pos_x_3d_0', 'norm_pos_y_3d_0', \n",
    "    'diameter_3d_0', \n",
    "    'ellipse_center_x_3d_0', 'ellipse_center_y_3d_0', 'ellipse_axis_a_3d_0', 'ellipse_axis_b_3d_0', 'ellipse_angle_3d_0', \n",
    "    # 'diameter_3d_3d_0', \n",
    "    # 'model_confidence_3d_0', \n",
    "    'sphere_center_x_3d_0', 'sphere_center_y_3d_0', 'sphere_center_z_3d_0', 'sphere_radius_3d_0', \n",
    "    'circle_3d_center_x_3d_0', 'circle_3d_center_y_3d_0', 'circle_3d_center_z_3d_0', \n",
    "    'circle_3d_normal_x_3d_0', 'circle_3d_normal_y_3d_0', 'circle_3d_normal_z_3d_0', \n",
    "    'circle_3d_radius_3d_0', \n",
    "    'theta_3d_0', 'phi_3d_0', \n",
    "    # 'projected_sphere_center_x_3d_0', 'projected_sphere_center_y_3d_0', 'projected_sphere_axis_a_3d_0', 'projected_sphere_axis_b_3d_0', 'projected_sphere_angle_3d_0', \n",
    "    'norm_pos_x_3d_1', 'norm_pos_y_3d_1', \n",
    "    'diameter_3d_1', \n",
    "    'ellipse_center_x_3d_1', 'ellipse_center_y_3d_1', 'ellipse_axis_a_3d_1', 'ellipse_axis_b_3d_1', 'ellipse_angle_3d_1', \n",
    "    # 'diameter_3d_3d_1', \n",
    "    # 'model_confidence_3d_1', \n",
    "    'sphere_center_x_3d_1', 'sphere_center_y_3d_1', 'sphere_center_z_3d_1', 'sphere_radius_3d_1', \n",
    "    'circle_3d_center_x_3d_1', 'circle_3d_center_y_3d_1', 'circle_3d_center_z_3d_1', \n",
    "    'circle_3d_normal_x_3d_1', 'circle_3d_normal_y_3d_1', 'circle_3d_normal_z_3d_1', \n",
    "    'circle_3d_radius_3d_1', \n",
    "    'theta_3d_1', 'phi_3d_1', \n",
    "    # 'projected_sphere_center_x_3d_1', 'projected_sphere_center_y_3d_1', 'projected_sphere_axis_a_3d_1', 'projected_sphere_axis_b_3d_1', 'projected_sphere_angle_3d_1'\n",
    "]\n",
    "\n",
    "\n",
    "other_cols = ['pupil_timestamp']\n",
    "\n",
    "\n",
    "dir_files = os.listdir(conf.DATASET_PATH)\n",
    "test_participants = ['10', '02']\n",
    "train_files = [os.path.join(conf.DATASET_PATH, f) for f in dir_files if f.split('_')[0] not in test_participants and f.endswith('.csv')]\n",
    "test_files = [os.path.join(conf.DATASET_PATH, f) for f in dir_files if f.split('_')[0] in test_participants and f.endswith('.csv')]\n",
    "\n",
    "train_ds = GazeDataset(train_files, col_of_interest, 300, min_confidence=0.5)\n",
    "test_ds = GazeDataset(test_files, col_of_interest, 300, min_confidence=0.5)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "all_data = np.concatenate([train_ds.data, test_ds.data])\n",
    "all_data = all_data.reshape(-1, all_data.shape[-1])\n",
    "scaler.fit(all_data.reshape(-1, all_data.shape[-1]))\n",
    "\n",
    "with open('../.local/scaler.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "train_ds.data = scaler.transform(train_ds.data.reshape(-1, train_ds.data.shape[-1])).reshape(train_ds.data.shape)\n",
    "test_ds.data = scaler.transform(test_ds.data.reshape(-1, test_ds.data.shape[-1])).reshape(test_ds.data.shape)\n",
    "\n",
    "print(f\"Training dataset shape: {train_ds.data.shape}\")\n",
    "print(f\"Test dataset shape: {test_ds.data.shape}\")\n",
    "print(f\"Shape of each sample: {train_ds[0][0].shape}\")\n",
    "print(f\"Unique classes: {list(train_ds.CLASS_MAP.keys())}\")\n",
    "\n",
    "# print the number of nan values in the dataset\n",
    "print(f\"Number of NaN values in the training dataset: {np.isnan(train_ds.data).sum()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (702, 300, 58)\n",
      "Test dataset shape: (165, 300, 58)\n",
      "Shape of each sample: (300, 58)\n",
      "Unique classes: ['Inspection', 'Reading', 'Search']\n",
      "Number of NaN values in the training dataset: 0\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "c18083b810a2d156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:36:29.726667Z",
     "start_time": "2024-10-17T13:36:28.552702Z"
    }
   },
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from datetime import datetime\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_SIZE = len(col_of_interest)\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 1\n",
    "NUM_CLASSES = 3\n",
    "LEARNING_RATE = 0.0003\n",
    "MODEL_TYPE = 'LSTM'\n",
    "DROPOUT = 0.3\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "GRAD_CLIP = 0.8\n",
    "OPT_STEP_SIZE = 10\n",
    "OPT_GAMMA = 0.9\n",
    "OPT_WD = 0.000001\n",
    "\n",
    "\n",
    "# Initialize the DataModule\n",
    "data_module = GazeDataModule(\n",
    "    train_ds, test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = GazeRNN(\n",
    "    input_size=len(col_of_interest),\n",
    "    hidden_size=HIDDEN_SIZE, \n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_classes=NUM_CLASSES, \n",
    "    learning_rate=LEARNING_RATE,\n",
    "    rnn_type=MODEL_TYPE,\n",
    "    opt_step_size=OPT_STEP_SIZE,\n",
    "    opt_gamma=OPT_GAMMA,\n",
    "    dropout=DROPOUT,\n",
    "    opt_wd=OPT_WD\n",
    ")\n",
    "\n",
    "# Checkpoint callback\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath=conf.MODEL_CHKPT_PATH + f'{MODEL_TYPE}/{current_time}',\n",
    "    filename='gaze_rnn-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "# Initialize PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=NUM_EPOCHS, \n",
    "    accelerator='gpu', \n",
    "    enable_progress_bar=True,\n",
    "    logger=False,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    #gradient_clip_val=GRAD_CLIP\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/Desktop/Uni/IMP/IMP_Magical_Gaze-based_Device_Control/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | rnn       | LSTM               | 31.7 K | train\n",
      "1 | fc        | Linear             | 195    | train\n",
      "2 | criterion | CrossEntropyLoss   | 0      | train\n",
      "3 | train_acc | MulticlassAccuracy | 0      | train\n",
      "4 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "31.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.9 K    Total params\n",
      "0.128     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddf601972b5a402ca589b46e4683d337"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5891415b19b346448a411ad26a04ff7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8132789daf7a47b9b5af7c3ddf9ff299"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00bff32ebd4e4a308ec1807066ad29dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "5885d90115cd851b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:38:22.954480Z",
     "start_time": "2024-10-17T13:38:22.707151Z"
    }
   },
   "source": [
    "# Load the best model from the checkpoint\n",
    "INPUT_SIZE = len(col_of_interest)\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 3\n",
    "NUM_CLASSES = 3\n",
    "LEARNING_RATE = 0.0003\n",
    "MODEL_TYPE = 'LSTM'\n",
    "DROPOUT = 0.3\n",
    "\n",
    "best_model = GazeRNN.load_from_checkpoint(\n",
    "    '../.local/checkpoints/LSTM/2024-10-17_15-12/gaze_rnn-epoch=25-val_loss=0.47.ckpt',#checkpoint_callback.best_model_path,\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    rnn_type=MODEL_TYPE,\n",
    "    dropout=DROPOUT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    opt_step_size=OPT_STEP_SIZE,\n",
    "    opt_gamma=OPT_GAMMA\n",
    ")\n",
    "\n",
    "# Predict on the validation set and set device to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# Initialize the DataLoader for the validation set\n",
    "val_loader = data_module.val_dataloader()\n",
    "\n",
    "# Predict on the validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for inputs, labels in val_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = best_model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    y_true.extend(labels.cpu().numpy())\n",
    "    y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "# Calculate the accuracy\n",
    "accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GazeRNN:\n\tMissing key(s) in state_dict: \"rnn.weight_ih_l2\", \"rnn.weight_hh_l2\", \"rnn.bias_ih_l2\", \"rnn.bias_hh_l2\". \n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([128, 37]) from checkpoint, the shape in current model is torch.Size([512, 58]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.weight_ih_l1: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.weight_hh_l1: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([3, 32]) from checkpoint, the shape in current model is torch.Size([3, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m MODEL_TYPE \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLSTM\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      8\u001B[0m DROPOUT \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.3\u001B[39m\n\u001B[0;32m---> 10\u001B[0m best_model \u001B[38;5;241m=\u001B[39m \u001B[43mGazeRNN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../.local/checkpoints/LSTM/2024-10-17_15-12/gaze_rnn-epoch=25-val_loss=0.47.ckpt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;66;43;03m#checkpoint_callback.best_model_path,\u001B[39;49;00m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mINPUT_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mHIDDEN_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNUM_LAYERS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNUM_CLASSES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrnn_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_TYPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDROPOUT\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mLEARNING_RATE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopt_step_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mOPT_STEP_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopt_gamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mOPT_GAMMA\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Predict on the validation set and set device to GPU\u001B[39;00m\n\u001B[1;32m     24\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/Uni/IMP/IMP_Magical_Gaze-based_Device_Control/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001B[0m, in \u001B[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m instance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scripting:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe classmethod `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` cannot be called on an instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    123\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Please call it on the class type and make sure the return value is used.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    124\u001B[0m     )\n\u001B[0;32m--> 125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Uni/IMP/IMP_Magical_Gaze-based_Device_Control/.venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1582\u001B[0m, in \u001B[0;36mLightningModule.load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;129m@_restricted_classmethod\u001B[39m\n\u001B[1;32m   1494\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_checkpoint\u001B[39m(\n\u001B[1;32m   1495\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   1501\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1580\u001B[0m \n\u001B[1;32m   1581\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1582\u001B[0m     loaded \u001B[38;5;241m=\u001B[39m \u001B[43m_load_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1583\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhparams_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1588\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1589\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1590\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Self, loaded)\n",
      "File \u001B[0;32m~/Desktop/Uni/IMP/IMP_Magical_Gaze-based_Device_Control/.venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:91\u001B[0m, in \u001B[0;36m_load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _load_state(\u001B[38;5;28mcls\u001B[39m, checkpoint, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, pl\u001B[38;5;241m.\u001B[39mLightningModule):\n\u001B[0;32m---> 91\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_state\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m     state_dict \u001B[38;5;241m=\u001B[39m checkpoint[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m state_dict:\n",
      "File \u001B[0;32m~/Desktop/Uni/IMP/IMP_Magical_Gaze-based_Device_Control/.venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:187\u001B[0m, in \u001B[0;36m_load_state\u001B[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001B[0m\n\u001B[1;32m    184\u001B[0m     obj\u001B[38;5;241m.\u001B[39mon_load_checkpoint(checkpoint)\n\u001B[1;32m    186\u001B[0m \u001B[38;5;66;03m# load the state_dict on the model automatically\u001B[39;00m\n\u001B[0;32m--> 187\u001B[0m keys \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstate_dict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m strict:\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m keys\u001B[38;5;241m.\u001B[39mmissing_keys:\n",
      "File \u001B[0;32m~/Desktop/Uni/IMP/IMP_Magical_Gaze-based_Device_Control/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[0;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[1;32m   2210\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[1;32m   2211\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2212\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[1;32m   2214\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2215\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2216\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[1;32m   2217\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for GazeRNN:\n\tMissing key(s) in state_dict: \"rnn.weight_ih_l2\", \"rnn.weight_hh_l2\", \"rnn.bias_ih_l2\", \"rnn.bias_hh_l2\". \n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([128, 37]) from checkpoint, the shape in current model is torch.Size([512, 58]).\n\tsize mismatch for rnn.weight_hh_l0: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.weight_ih_l1: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.weight_hh_l1: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for rnn.bias_ih_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for rnn.bias_hh_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([3, 32]) from checkpoint, the shape in current model is torch.Size([3, 128])."
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "20bc6b132cb9c6ab",
   "metadata": {},
   "source": [
    "# Plot the confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=GazeDataset.CLASS_MAP.keys(), yticklabels=GazeDataset.CLASS_MAP.keys(), cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7c30defb8c8a73b3",
   "metadata": {},
   "source": [
    "import msgpack\n",
    "import cv2\n",
    "import numpy as np\n",
    "import zmq\n",
    "from PIL import Image\n",
    "import socket\n",
    "import toml\n",
    "\n",
    "\n",
    "app_config = toml.load(\"../Dashboard_App/config.toml\")\n",
    "\n",
    "def decode_dict(d):\n",
    "    result = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(key, bytes):\n",
    "            key = key.decode()\n",
    "        if isinstance(value, bytes):\n",
    "            value = value.decode()\n",
    "        elif isinstance(value, dict):\n",
    "            value = decode_dict(value)\n",
    "        result.update({key: value})\n",
    "    return result\n",
    "\n",
    "\n",
    "class PupilLabsController:\n",
    "    TOPIC_GAZE = app_config[\"pupil_topics\"][\"gaze\"]\n",
    "    TOPIC_FRAME_WORLD = app_config[\"pupil_topics\"][\"front_camera\"]\n",
    "    SERVICE_HOST = app_config[\"pupil_service\"][\"host\"]\n",
    "    SERVICE_PORT = app_config[\"pupil_service\"][\"port\"]\n",
    "\n",
    "    def __init__(self):\n",
    "        if self.is_service_online():\n",
    "            self.ctx = zmq.Context()\n",
    "            self.sub_port, self.pub_port = self.__get_sub_pub_ports()\n",
    "\n",
    "            self.gaze_socket = self.__create_pupil_sub_socket(self.TOPIC_GAZE)\n",
    "            self.frame_world_socket = self.__create_pupil_sub_socket(self.TOPIC_FRAME_WORLD)\n",
    "        else:\n",
    "            raise ConnectionError(\"Pupil service is offline or not reachable.\")\n",
    "\n",
    "    def reconnect_sockets(self):\n",
    "        self.gaze_socket.close()\n",
    "        self.frame_world_socket.close()\n",
    "        self.gaze_socket = self.__create_pupil_sub_socket(self.TOPIC_GAZE)\n",
    "        self.frame_world_socket = self.__create_pupil_sub_socket(self.TOPIC_FRAME_WORLD)\n",
    "\n",
    "    def receive_gaze_data(self, num_gazes=1):\n",
    "        gazes = []\n",
    "        for _ in range(num_gazes):\n",
    "            topic, payload = self.gaze_socket.recv_multipart()\n",
    "            message = msgpack.loads(payload)\n",
    "\n",
    "            # Decode the message\n",
    "            gaze = decode_dict(message)\n",
    "            gaze[\"base_data\"] = [decode_dict(data) for data in gaze[\"base_data\"]]\n",
    "\n",
    "            gazes.append(gaze)\n",
    "        return gazes\n",
    "\n",
    "    def receive_cam_frames(self, num_frames=1):\n",
    "        frames = []\n",
    "        for _ in range(num_frames):\n",
    "            _, _, payload = self.frame_world_socket.recv_multipart()\n",
    "\n",
    "            # Decode the image\n",
    "            frame = cv2.imdecode(np.frombuffer(payload, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "            # Convert the image to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            frame = Image.fromarray(frame)\n",
    "            frames.append(frame)\n",
    "        return frames\n",
    "\n",
    "    def close_connection(self):\n",
    "        self.ctx.term()\n",
    "\n",
    "    def is_service_online(self):\n",
    "        \"\"\"Check if the service is online by attempting to connect to it.\"\"\"\n",
    "        try:\n",
    "            # Create a socket object\n",
    "            with socket.create_connection((self.SERVICE_HOST, self.SERVICE_PORT), timeout=5):\n",
    "                return True  # Service is online\n",
    "        except (socket.timeout, ConnectionRefusedError):\n",
    "            return False  # Service is offline or not reachable\n",
    "\n",
    "    def __create_pupil_sub_socket(self, topic=None):\n",
    "        pupil_socket = self.ctx.socket(zmq.SUB)\n",
    "        pupil_socket.connect(f'tcp://{self.SERVICE_HOST}:{self.sub_port}')\n",
    "        pupil_socket.subscribe(topic)\n",
    "        return pupil_socket\n",
    "\n",
    "    def __create_pupil_req_socket(self):\n",
    "        pupil_socket = self.ctx.socket(zmq.REQ)\n",
    "        pupil_socket.connect(f'tcp://{self.SERVICE_HOST}:{self.SERVICE_PORT}')\n",
    "        return pupil_socket\n",
    "\n",
    "    def __get_sub_pub_ports(self):\n",
    "        pupil_socket = self.__create_pupil_req_socket()\n",
    "\n",
    "        pupil_socket.send_string('SUB_PORT')\n",
    "        sub_port = pupil_socket.recv_string()\n",
    "\n",
    "        pupil_socket.send_string('PUB_PORT')\n",
    "        pub_port = pupil_socket.recv_string()\n",
    "\n",
    "        pupil_socket.close()\n",
    "\n",
    "        return sub_port, pub_port\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def dict_to_dataframe(data_dict, col_of_interest):\n",
    "    \n",
    "    # Initialize a dictionary for the DataFrame\n",
    "    df_data = {col: [np.nan] for col in col_of_interest}\n",
    "    \n",
    "    # Populate the dictionary with data from data_dict\n",
    "    for eye_data in data_dict.get('base_data', []):\n",
    "        eye_id = eye_data['id']\n",
    "        \n",
    "        # 2D data\n",
    "        df_data[f'norm_pos_x_2d_{eye_id}'][0] = eye_data['norm_pos'][0]\n",
    "        df_data[f'norm_pos_y_2d_{eye_id}'][0] = eye_data['norm_pos'][1]\n",
    "        df_data[f'diameter_2d_{eye_id}'][0] = eye_data['diameter']\n",
    "        df_data[f'ellipse_center_x_2d_{eye_id}'][0] = eye_data['ellipse']['center'][0]\n",
    "        df_data[f'ellipse_center_y_2d_{eye_id}'][0] = eye_data['ellipse']['center'][1]\n",
    "        df_data[f'ellipse_axis_a_2d_{eye_id}'][0] = eye_data['ellipse']['axes'][0]\n",
    "        df_data[f'ellipse_axis_b_2d_{eye_id}'][0] = eye_data['ellipse']['axes'][1]\n",
    "        df_data[f'ellipse_angle_2d_{eye_id}'][0] = eye_data['ellipse']['angle']\n",
    "        \n",
    "        # 3D data\n",
    "        df_data[f'norm_pos_x_3d_{eye_id}'][0] = eye_data['norm_pos'][0]\n",
    "        df_data[f'norm_pos_y_3d_{eye_id}'][0] = eye_data['norm_pos'][1]\n",
    "        df_data[f'diameter_3d_{eye_id}'][0] = eye_data['diameter_3d']\n",
    "        df_data[f'ellipse_center_x_3d_{eye_id}'][0] = eye_data['ellipse']['center'][0]\n",
    "        df_data[f'ellipse_center_y_3d_{eye_id}'][0] = eye_data['ellipse']['center'][1]\n",
    "        df_data[f'ellipse_axis_a_3d_{eye_id}'][0] = eye_data['ellipse']['axes'][0]\n",
    "        df_data[f'ellipse_axis_b_3d_{eye_id}'][0] = eye_data['ellipse']['axes'][1]\n",
    "        df_data[f'ellipse_angle_3d_{eye_id}'][0] = eye_data['ellipse']['angle']\n",
    "        \n",
    "        df_data[f'sphere_center_x_3d_{eye_id}'][0] = eye_data['sphere']['center'][0]\n",
    "        df_data[f'sphere_center_y_3d_{eye_id}'][0] = eye_data['sphere']['center'][1]\n",
    "        df_data[f'sphere_center_z_3d_{eye_id}'][0] = eye_data['sphere']['center'][2]\n",
    "        df_data[f'sphere_radius_3d_{eye_id}'][0] = eye_data['sphere']['radius']\n",
    "        \n",
    "        df_data[f'circle_3d_center_x_3d_{eye_id}'][0] = eye_data['circle_3d']['center'][0]\n",
    "        df_data[f'circle_3d_center_y_3d_{eye_id}'][0] = eye_data['circle_3d']['center'][1]\n",
    "        df_data[f'circle_3d_center_z_3d_{eye_id}'][0] = eye_data['circle_3d']['center'][2]\n",
    "        \n",
    "        df_data[f'circle_3d_normal_x_3d_{eye_id}'][0] = eye_data['circle_3d']['normal'][0]\n",
    "        df_data[f'circle_3d_normal_y_3d_{eye_id}'][0] = eye_data['circle_3d']['normal'][1]\n",
    "        df_data[f'circle_3d_normal_z_3d_{eye_id}'][0] = eye_data['circle_3d']['normal'][2]\n",
    "        df_data[f'circle_3d_radius_3d_{eye_id}'][0] = eye_data['circle_3d']['radius']\n",
    "        \n",
    "        df_data[f'theta_3d_{eye_id}'][0] = eye_data['theta']\n",
    "        df_data[f'phi_3d_{eye_id}'][0] = eye_data['phi']\n",
    "    \n",
    "    # Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(df_data)\n",
    "    return df"
   ],
   "id": "888b81b749136156",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "\n",
    "col_of_interest = [\n",
    "    'norm_pos_x_2d_0', 'norm_pos_y_2d_0', 'diameter_2d_0', \n",
    "    'ellipse_center_x_2d_0', 'ellipse_center_y_2d_0', 'ellipse_axis_a_2d_0', 'ellipse_axis_b_2d_0', 'ellipse_angle_2d_0', \n",
    "    'norm_pos_x_2d_1', 'norm_pos_y_2d_1', 'diameter_2d_1', \n",
    "    'ellipse_center_x_2d_1', 'ellipse_center_y_2d_1', 'ellipse_axis_a_2d_1', 'ellipse_axis_b_2d_1', 'ellipse_angle_2d_1', \n",
    "    'norm_pos_x_3d_0', 'norm_pos_y_3d_0', 'diameter_3d_0', \n",
    "    'ellipse_center_x_3d_0', 'ellipse_center_y_3d_0', 'ellipse_axis_a_3d_0', 'ellipse_axis_b_3d_0', 'ellipse_angle_3d_0', \n",
    "    'sphere_center_x_3d_0', 'sphere_center_y_3d_0', 'sphere_center_z_3d_0', 'sphere_radius_3d_0', \n",
    "    'circle_3d_center_x_3d_0', 'circle_3d_center_y_3d_0', 'circle_3d_center_z_3d_0', \n",
    "    'circle_3d_normal_x_3d_0', 'circle_3d_normal_y_3d_0', 'circle_3d_normal_z_3d_0', \n",
    "    'circle_3d_radius_3d_0', 'theta_3d_0', 'phi_3d_0', \n",
    "    'norm_pos_x_3d_1', 'norm_pos_y_3d_1', 'diameter_3d_1', \n",
    "    'ellipse_center_x_3d_1', 'ellipse_center_y_3d_1', 'ellipse_axis_a_3d_1', 'ellipse_axis_b_3d_1', 'ellipse_angle_3d_1', \n",
    "    'sphere_center_x_3d_1', 'sphere_center_y_3d_1', 'sphere_center_z_3d_1', 'sphere_radius_3d_1', \n",
    "    'circle_3d_center_x_3d_1', 'circle_3d_center_y_3d_1', 'circle_3d_center_z_3d_1', \n",
    "    'circle_3d_normal_x_3d_1', 'circle_3d_normal_y_3d_1', 'circle_3d_normal_z_3d_1', \n",
    "    'circle_3d_radius_3d_1', 'theta_3d_1', 'phi_3d_1',\n",
    "]\n",
    "\n",
    "pupil_cap = PupilLabsController()\n",
    "\n",
    "gaze_data = pupil_cap.receive_gaze_data(300)\n",
    "pprint.pprint(gaze_data[0])\n",
    "\n",
    "# convert the gaze data to a DataFrame\n",
    "gaze_df = dict_to_dataframe(gaze_data[0], col_of_interest)\n",
    "\n",
    "for i in range(1, len(gaze_data)):\n",
    "    gaze_df = pd.concat([gaze_df, dict_to_dataframe(gaze_data[i], col_of_interest)], ignore_index=True)\n",
    "\n",
    "print(f\"Shape of the gaze DataFrame: {gaze_df.shape}\")\n",
    "\n",
    "# Print the number of NaN values in the DataFrame for each column\n",
    "for col in gaze_df.columns:\n",
    "    print(f\"{gaze_df[col].isna().sum()} : {col}\")\n",
    "\n",
    "# Interpolate the data\n",
    "gaze_df = gaze_df.replace([np.inf, -np.inf], np.nan)\n",
    "gaze_df = gaze_df.interpolate(method='linear')\n",
    "gaze_df = gaze_df.dropna()\n",
    "\n",
    "# Scale the data\n",
    "print(gaze_df.values.shape)\n",
    "gaze_df = scaler.transform(gaze_df.values)\n",
    "\n",
    "# Convert the DataFrame to a PyTorch tensor\n",
    "gaze_tensor = torch.tensor(gaze_df, dtype=torch.float32).unsqueeze(0)\n",
    "gaze_tensor = gaze_tensor.to(device)\n",
    "\n",
    "# Predict the class\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = best_model(gaze_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "predicted_class = list(GazeDataset.CLASS_MAP.keys())[predicted.item()]\n",
    "print(f\"Predicted class: {predicted}\")\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ],
   "id": "8ca2266f040f6986",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pupil_cap = PupilLabsController()\n",
    "\n",
    "for i in range(10):\n",
    "    pupil_cap.reconnect_sockets()\n",
    "    gaze_data = pupil_cap.receive_gaze_data(300)\n",
    "    \n",
    "    # convert the gaze data to a DataFrame\n",
    "    gaze_df = dict_to_dataframe(gaze_data[0], col_of_interest)\n",
    "    \n",
    "    for i in range(1, len(gaze_data)):\n",
    "        gaze_df = pd.concat([gaze_df, dict_to_dataframe(gaze_data[i], col_of_interest)], ignore_index=True)\n",
    "\n",
    "    # Interpolate the data\n",
    "    gaze_df = gaze_df.replace([np.inf, -np.inf], np.nan)\n",
    "    gaze_df = gaze_df.interpolate(method='linear')\n",
    "    gaze_df = gaze_df.dropna()\n",
    "    \n",
    "    # Scale the data\n",
    "    gaze_df = scaler.transform(gaze_df.values)\n",
    "    \n",
    "    # Convert the DataFrame to a PyTorch tensor\n",
    "    gaze_tensor = torch.tensor(gaze_df, dtype=torch.float32).unsqueeze(0)\n",
    "    gaze_tensor = gaze_tensor.to(device)\n",
    "    \n",
    "    # Predict the class\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(gaze_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "    predicted_class = list(GazeDataset.CLASS_MAP.keys())[predicted.item()]\n",
    "    print(f\"Predicted class: {predicted}\")\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "    print()"
   ],
   "id": "bbb90b027091af9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:24:14.773197Z",
     "start_time": "2024-10-17T13:24:14.765678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class CustomEarlyStopping(Callback):\n",
    "    def __init__(self, patience, loss_tr):\n",
    "        super().__init__()\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.loss_tr = loss_tr\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Get the latest validation and training accuracy\n",
    "        val_loss = trainer.callback_metrics.get('val_loss_epoch')\n",
    "        train_loss = trainer.callback_metrics.get('train_loss_epoch')\n",
    "\n",
    "        # Check if val_acc is smaller than train_acc_epoch\n",
    "        if val_loss is not None and train_loss is not None:\n",
    "            if val_loss > train_loss + self.loss_tr:\n",
    "                self.counter += 1\n",
    "                print(f\"Validation accuracy ({val_loss:.4f}) is less than training accuracy ({train_loss:.4f}). Counter: {self.counter}/{self.patience}\")\n",
    "            else:\n",
    "                self.counter = 0  # Reset counter if condition is not met\n",
    "\n",
    "            # Stop training if the condition is met for `patience` consecutive epochs\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"Early stopping: Validation accuracy did not improve compared to training accuracy for 3 consecutive epochs.\")\n",
    "                trainer.should_stop = True"
   ],
   "id": "4967ce85ccb5d76c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "from datetime import datetime\n",
    "\n",
    "WANDB_PROJECT = 'gaze_lstm_hp_tuning'\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(project=WANDB_PROJECT)\n",
    "\n",
    "# Sweep configuration for hyperparameter tuning\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': list(np.linspace(0.00001, 0.0003, 10))\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [128]\n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [8, 16, 32]\n",
    "        },\n",
    "        'num_layers': {\n",
    "            'values': [1, 2, 3]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': list(np.linspace(0.2, 0.5, 10))\n",
    "        },\n",
    "        'opt_step_size': {\n",
    "            'values': [20]\n",
    "        },\n",
    "        'opt_gamma': {\n",
    "            'values': [0.8]\n",
    "        },\n",
    "        'opt_wd': {\n",
    "            'values': [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "        },\n",
    "        'grad_clip': {\n",
    "            'values': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "HP_NUM_CLASSES = 3\n",
    "HP_MODEL_TYPE = 'LSTM'\n",
    "HP_NUM_EPOCHS = 100\n",
    "HP_NUM_WORKERS = 6\n",
    "HP_EARLY_STOPPING = 5\n",
    "HP_LOSS_TR = 0.2\n",
    "\n",
    "# Sweep ID\n",
    "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT)\n",
    "\n",
    "# Define training function\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        # Hyperparameters from WandB config\n",
    "        learning_rate = config.learning_rate\n",
    "        batch_size = config.batch_size\n",
    "        hidden_size = config.hidden_size\n",
    "        num_layers = config.num_layers\n",
    "        dropout = config.dropout\n",
    "        opt_step_size = config.opt_step_size\n",
    "        opt_gamma = config.opt_gamma\n",
    "        opt_wd = config.opt_wd\n",
    "        grad_clip = config.grad_clip\n",
    "\n",
    "        # Initialize DataModule with current hyperparameters\n",
    "        data_module = GazeDataModule(\n",
    "            train_ds, test_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=HP_NUM_WORKERS\n",
    "        )\n",
    "\n",
    "        # Initialize the model with current hyperparameters\n",
    "        model = GazeRNN(\n",
    "            input_size=len(col_of_interest),\n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            num_classes=HP_NUM_CLASSES, \n",
    "            learning_rate=learning_rate,\n",
    "            rnn_type=HP_MODEL_TYPE,\n",
    "            opt_step_size=opt_step_size,\n",
    "            opt_gamma=opt_gamma,\n",
    "            dropout=dropout,\n",
    "            opt_wd=opt_wd\n",
    "        )\n",
    "\n",
    "        # Checkpoint callback\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "\n",
    "        # Wandb Logger\n",
    "        wandb_logger = WandbLogger(project=WANDB_PROJECT)\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping_1 = CustomEarlyStopping(patience=HP_EARLY_STOPPING, loss_tr=HP_LOSS_TR)\n",
    "        # early_stopping_2 = EarlyStopping(monitor='val_acc', patience=HP_EARLY_STOPPING, mode='max')\n",
    "        \n",
    "\n",
    "        # Trainer with Wandb logger and checkpointing\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=HP_NUM_EPOCHS, \n",
    "            accelerator='gpu', \n",
    "            enable_progress_bar=True,\n",
    "            logger=wandb_logger,\n",
    "            enable_checkpointing=False,\n",
    "            callbacks=[early_stopping_1],\n",
    "            gradient_clip_val=grad_clip,\n",
    "            log_every_n_steps=10,\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, data_module)\n",
    "\n",
    "# Run the sweep\n",
    "wandb.agent(sweep_id, train, count=50)"
   ],
   "id": "e1972baf3cf048b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fba58fa4c948473",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e67297573fed6648",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
